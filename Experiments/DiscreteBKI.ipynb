{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is  cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import time\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "# For visualizer\n",
    "import rospy\n",
    "from ContinuousBKI import *\n",
    "from visualization_msgs.msg import *\n",
    "rospy.init_node('talker',disable_signals=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device == \"cuda\":\n",
    "  start = torch.cuda.Event(enable_timing=True)\n",
    "  end = torch.cuda.Event(enable_timing=True)\n",
    "else:\n",
    "  start = None\n",
    "  end = None\n",
    "print(\"device is \", device)\n",
    "    \n",
    "home_dir = os.path.expanduser('~')\n",
    "dataset_loc = os.path.join(home_dir, \"Data/Rellis-3D/00004/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteBKI(torch.nn.Module):\n",
    "    def __init__(self, grid_size, min_bound, max_bound, filter_size=3,\n",
    "                 num_classes=21, prior=0.001, device=\"cpu\",\n",
    "                max_dist=0.5):\n",
    "        '''\n",
    "        Input:\n",
    "            grid_size: (x, y, z) int32 array, number of voxels\n",
    "            min_bound: (x, y, z) float32 array, lower bound on local map\n",
    "            max_bound: (x, y, z) float32 array, upper bound on local map\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.min_bound = min_bound.view(-1, 3).to(device)\n",
    "        self.max_bound = max_bound.view(-1, 3).to(device)\n",
    "        self.grid_size = grid_size\n",
    "        self.prior = prior\n",
    "\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.voxel_sizes = (self.max_bound.view(-1) - self.min_bound.view(-1)) / self.grid_size.to(self.device)\n",
    "        \n",
    "        self.pi = torch.acos(torch.zeros(1)).item() * 2\n",
    "        self.max_dist = max_dist\n",
    "        self.filter_size = torch.tensor(filter_size).to(self.device)\n",
    "        self.initialize_kernel()\n",
    "        \n",
    "        [xs, ys, zs] = [(max_bound[i]-min_bound[i])/(2*grid_size[i]) + \n",
    "                        torch.linspace(min_bound[i], max_bound[i], device=device, steps=grid_size[i]+1)[:-1] \n",
    "                        for i in range(3)]\n",
    "        self.centroids = torch.cartesian_prod(xs, ys, zs).to(device)\n",
    "    \n",
    "    def initialize_kernel(self):\n",
    "        # Initialize with sparse kernel\n",
    "        weights = []\n",
    "        assert(self.filter_size % 2 == 1)\n",
    "        middle_ind = torch.floor(self.filter_size / 2)\n",
    "        \n",
    "        self.sigma = torch.nn.Parameter(torch.tensor(1.0)) # Kernel must map to 0 to 1\n",
    "        self.ell = torch.nn.Parameter(torch.tensor(self.max_dist)) # Max distance to consider\n",
    "        \n",
    "        for x_ind in range(self.filter_size):\n",
    "            for y_ind in range(self.filter_size):\n",
    "                for z_ind in range(self.filter_size):\n",
    "                    x_dist = torch.abs(x_ind - middle_ind) * self.voxel_sizes[0]\n",
    "                    y_dist = torch.abs(y_ind - middle_ind) * self.voxel_sizes[1]\n",
    "                    z_dist = torch.abs(z_ind - middle_ind) * self.voxel_sizes[2]\n",
    "                    total_dist = torch.sqrt(x_dist**2 + y_dist**2 + z_dist**2)\n",
    "                    kernel_value = self.calculate_kernel(total_dist)\n",
    "                    # Edge case: middle\n",
    "                    if total_dist == 0:\n",
    "                        weights.append(1.0)\n",
    "                    else:\n",
    "                        weight = self.inverse_sigmoid(kernel_value)\n",
    "                        weights.append(torch.nn.Parameter(weight))\n",
    "        self.weights = weights\n",
    "                    \n",
    "    def inverse_sigmoid(self, x):\n",
    "        return -torch.log((1 / (x + 1e-8)) - 1)\n",
    "            \n",
    "            \n",
    "    def calculate_kernel(self, d):\n",
    "        if d > self.max_dist:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        if d == 0:\n",
    "            return 1\n",
    "        return self.sigma * ( \n",
    "                (1/3)*(2 + torch.cos(2 * self.pi * d/self.ell))*(1 - d/self.ell) +\n",
    "                         1/(2*self.pi) * torch.sin(2 * self.pi * d / self.ell)\n",
    "                         )\n",
    "            \n",
    "            \n",
    "    def initialize_grid(self):\n",
    "        return torch.zeros(self.grid_size[0], self.grid_size[1], self.grid_size[2], \n",
    "                           self.num_classes, device=self.device) + self.prior\n",
    "    \n",
    "    def grid_ind(self, input_pc):\n",
    "        '''\n",
    "        Input:\n",
    "            input_xyz: N * (x, y, z, c) float32 array, point cloud\n",
    "        Output:\n",
    "            grid_inds: N' * (x, y, z, c) int32 array, point cloud mapped to voxels\n",
    "        '''\n",
    "        input_xyz   = input_pc[:, :3]\n",
    "        labels      = input_pc[:, 3].view(-1, 1)\n",
    "        \n",
    "        valid_input_mask = torch.all((input_xyz < self.max_bound) & (input_xyz >= self.min_bound), axis=1)\n",
    "        \n",
    "        valid_xyz = input_xyz[valid_input_mask]\n",
    "        valid_labels = labels[valid_input_mask]\n",
    "        \n",
    "        grid_inds = torch.floor((valid_xyz - self.min_bound) / self.voxel_sizes)\n",
    "        maxes = (self.grid_size - 1).view(1, 3)\n",
    "        clipped_inds = torch.clamp(grid_inds, torch.zeros_like(maxes), maxes)\n",
    "        \n",
    "        return torch.hstack( (clipped_inds, valid_labels) )\n",
    "        \n",
    "        \n",
    "    def forward(self, current_map, point_cloud):\n",
    "        '''\n",
    "        Input:\n",
    "            current_map: (x, y, z, c) float32 array, prior dirichlet distribution over map\n",
    "            point_cloud: N * (x, y, z, c) float32 array, semantically labeled points\n",
    "        Output:\n",
    "            updated_map: (x, y, z, c) float32 array, posterior dirichlet distribution over map\n",
    "        '''\n",
    "        # Assume map and point cloud are already aligned\n",
    "        X, Y, Z, C = current_map.shape\n",
    "        update = torch.zeros_like(current_map)\n",
    "        \n",
    "        # 1: Discretize\n",
    "        grid_pc = self.grid_ind(point_cloud).to(torch.long)\n",
    "       \n",
    "        unique_inds, counts = torch.unique(grid_pc, return_counts=True, dim=0)  \n",
    "        grid_indices = [unique_inds[:, i] for i in range(grid_pc.shape[1])]\n",
    "        \n",
    "        update[grid_indices] = update[grid_indices] + counts\n",
    "        \n",
    "        # 2: Apply BKI filters\n",
    "        filters = torch.sigmoid(torch.tensor(self.weights, device=self.device)).view(\n",
    "            1, 1, self.filter_size, self.filter_size, self.filter_size)\n",
    "        mid = torch.floor(self.filter_size / 2).to(torch.long)\n",
    "        filters[0, 0, mid, mid, mid] = 1\n",
    "        \n",
    "        update = torch.unsqueeze(update.permute(3, 0, 1, 2), 1)\n",
    "        update = F.conv3d(update, filters, padding=\"same\")\n",
    "        update = torch.squeeze(update).permute(1, 2, 3, 0)\n",
    "        \n",
    "        return current_map + update\n",
    "    \n",
    "    # def propagate(self, current_map, transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bki_map = DiscreteBKI(\n",
    "    torch.tensor([256, 256, 16]).to(device), # Grid size\n",
    "    torch.tensor([-25.6, -25.6, -2.0]).to(device), # Lower bound\n",
    "    torch.tensor([25.6, 25.6, 1.2]).to(device), # Upper bound\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Add visualization\n",
    "map_pub = rospy.Publisher('SemMap', MarkerArray, queue_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point cloud from RELLIS\n",
    "velo_loc = os.path.join(dataset_loc, \"os1_cloud_node_kitti_bin\")\n",
    "label_base_loc = os.path.join(dataset_loc, \"os1_cloud_node_semantickitti_label_id\")\n",
    "os_files = os.listdir(velo_loc)\n",
    "\n",
    "curr_frame_id=0\n",
    "end_frame_id=0\n",
    "for velo_file in sorted(os_files):\n",
    "    velo = np.fromfile(os.path.join(velo_loc, velo_file), dtype=np.float32).reshape(-1, 4)[:, :3]\n",
    "    velo = torch.from_numpy(velo).to(device)\n",
    "    labels = np.fromfile(os.path.join(label_base_loc, velo_file.split(\".\")[0]+\".label\"), dtype=np.uint32)\n",
    "    labels_remapped = torch.from_numpy(class_remap[labels]).to(device=device) # Remap labels to be contiguous\n",
    "    \n",
    "    # Ego vehicle = 0\n",
    "    non_void = labels_remapped != 0\n",
    "    velo = velo[non_void]\n",
    "    labels_remapped = labels_remapped[non_void]\n",
    "    \n",
    "    labeled_pc = torch.hstack( (velo, labels_remapped.reshape(-1, 1)) )\n",
    "    \n",
    "    non_dynamic = (labels_remapped != class_remap[8]) & (labels_remapped != class_remap[17])\n",
    "    labeled_pc = labeled_pc[non_dynamic]\n",
    "    \n",
    "    current_map = bki_map.initialize_grid()\n",
    "    posterior_map = bki_map(current_map, labeled_pc)\n",
    "\n",
    "    if curr_frame_id==end_frame_id:\n",
    "        break\n",
    "    curr_frame_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, D, _ = posterior_map.shape\n",
    "\n",
    "publish_voxels(posterior_map, map_pub, \n",
    "    bki_map.centroids, \n",
    "    bki_map.min_bound.reshape(-1), \n",
    "    bki_map.max_bound.reshape(-1), \n",
    "    bki_map.grid_size.reshape(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Test 3D conv\n",
    "\n",
    "num_classes = 20\n",
    "\n",
    "# X, Y, Z\n",
    "filters = torch.zeros(27, dtype=torch.float)\n",
    "filters[13] = 1\n",
    "filters = filters.view(1, 1, 3, 3, 3)\n",
    "\n",
    "print(filters[0, 0, 1, :, :])\n",
    "\n",
    "inputs = torch.ones(num_classes, 1, 5, 5, 5)\n",
    "\n",
    "output = F.conv3d(inputs, filters, padding=\"same\")\n",
    "print(output[0, 0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
