{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is  cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import time\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "# For visualizer\n",
    "import rospy\n",
    "from Data.utils import *\n",
    "from visualization_msgs.msg import *\n",
    "rospy.init_node('talker',disable_signals=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device == \"cuda\":\n",
    "  start = torch.cuda.Event(enable_timing=True)\n",
    "  end = torch.cuda.Event(enable_timing=True)\n",
    "else:\n",
    "  start = None\n",
    "  end = None\n",
    "print(\"device is \", device)\n",
    "    \n",
    "home_dir = os.path.expanduser('~')\n",
    "dataset_loc = os.path.join(home_dir, \"Data/Rellis-3D/sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteBKI(torch.nn.Module):\n",
    "    def __init__(self, grid_size, min_bound, max_bound, filter_size=3,\n",
    "                 num_classes=21, prior=0.001, device=\"cpu\",\n",
    "                max_dist=0.5):\n",
    "        '''\n",
    "        Input:\n",
    "            grid_size: (x, y, z) int32 array, number of voxels\n",
    "            min_bound: (x, y, z) float32 array, lower bound on local map\n",
    "            max_bound: (x, y, z) float32 array, upper bound on local map\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.min_bound = min_bound.view(-1, 3).to(device)\n",
    "        self.max_bound = max_bound.view(-1, 3).to(device)\n",
    "        self.grid_size = grid_size\n",
    "        self.prior = prior\n",
    "\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.voxel_sizes = (self.max_bound.view(-1) - self.min_bound.view(-1)) / self.grid_size.to(self.device)\n",
    "        \n",
    "        self.pi = torch.acos(torch.zeros(1)).item() * 2\n",
    "        self.max_dist = max_dist\n",
    "        self.filter_size = torch.tensor(filter_size).to(self.device)\n",
    "        self.initialize_kernel()\n",
    "        \n",
    "        [xs, ys, zs] = [(max_bound[i]-min_bound[i])/(2*grid_size[i]) + \n",
    "                        torch.linspace(min_bound[i], max_bound[i], device=device, steps=grid_size[i]+1)[:-1] \n",
    "                        for i in range(3)]\n",
    "        self.centroids = torch.cartesian_prod(xs, ys, zs).to(device)\n",
    "    \n",
    "    def initialize_kernel(self):\n",
    "        # Initialize with sparse kernel\n",
    "        weights = []\n",
    "        assert(self.filter_size % 2 == 1)\n",
    "        middle_ind = torch.floor(self.filter_size / 2)\n",
    "        \n",
    "        self.sigma = torch.nn.Parameter(torch.tensor(1.0)) # Kernel must map to 0 to 1\n",
    "        self.ell = torch.nn.Parameter(torch.tensor(self.max_dist)) # Max distance to consider\n",
    "        \n",
    "        for x_ind in range(self.filter_size):\n",
    "            for y_ind in range(self.filter_size):\n",
    "                for z_ind in range(self.filter_size):\n",
    "                    x_dist = torch.abs(x_ind - middle_ind) * self.voxel_sizes[0]\n",
    "                    y_dist = torch.abs(y_ind - middle_ind) * self.voxel_sizes[1]\n",
    "                    z_dist = torch.abs(z_ind - middle_ind) * self.voxel_sizes[2]\n",
    "                    total_dist = torch.sqrt(x_dist**2 + y_dist**2 + z_dist**2)\n",
    "                    kernel_value = self.calculate_kernel(total_dist)\n",
    "                    # Edge case: middle\n",
    "                    if total_dist == 0:\n",
    "                        weights.append(1.0)\n",
    "                    else:\n",
    "                        weight = self.inverse_sigmoid(kernel_value)\n",
    "                        weights.append(torch.nn.Parameter(weight))\n",
    "        self.weights = weights\n",
    "                    \n",
    "    def inverse_sigmoid(self, x):\n",
    "        return -torch.log((1 / (x + 1e-8)) - 1)\n",
    "            \n",
    "            \n",
    "    def calculate_kernel(self, d):\n",
    "        if d > self.max_dist:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        if d == 0:\n",
    "            return 1\n",
    "        return self.sigma * ( \n",
    "                (1/3)*(2 + torch.cos(2 * self.pi * d/self.ell))*(1 - d/self.ell) +\n",
    "                         1/(2*self.pi) * torch.sin(2 * self.pi * d / self.ell)\n",
    "                         )\n",
    "            \n",
    "            \n",
    "    def initialize_grid(self):\n",
    "        return torch.zeros(self.grid_size[0], self.grid_size[1], self.grid_size[2], \n",
    "                           self.num_classes, device=self.device) + self.prior\n",
    "    \n",
    "    def grid_ind(self, input_pc):\n",
    "        '''\n",
    "        Input:\n",
    "            input_xyz: N * (x, y, z, c) float32 array, point cloud\n",
    "        Output:\n",
    "            grid_inds: N' * (x, y, z, c) int32 array, point cloud mapped to voxels\n",
    "        '''\n",
    "        input_xyz   = input_pc[:, :3]\n",
    "        labels      = input_pc[:, 3].view(-1, 1)\n",
    "        \n",
    "        valid_input_mask = torch.all((input_xyz < self.max_bound) & (input_xyz >= self.min_bound), axis=1)\n",
    "        \n",
    "        valid_xyz = input_xyz[valid_input_mask]\n",
    "        valid_labels = labels[valid_input_mask]\n",
    "        \n",
    "        grid_inds = torch.floor((valid_xyz - self.min_bound) / self.voxel_sizes)\n",
    "        maxes = (self.grid_size - 1).view(1, 3)\n",
    "        clipped_inds = torch.clamp(grid_inds, torch.zeros_like(maxes), maxes)\n",
    "        \n",
    "        return torch.hstack( (clipped_inds, valid_labels) )\n",
    "        \n",
    "        \n",
    "    def forward(self, current_map, point_cloud):\n",
    "        '''\n",
    "        Input:\n",
    "            current_map: (x, y, z, c) float32 array, prior dirichlet distribution over map\n",
    "            point_cloud: N * (x, y, z, c) float32 array, semantically labeled points\n",
    "        Output:\n",
    "            updated_map: (x, y, z, c) float32 array, posterior dirichlet distribution over map\n",
    "        '''\n",
    "        # Assume map and point cloud are already aligned\n",
    "        X, Y, Z, C = current_map.shape\n",
    "        update = torch.zeros_like(current_map)\n",
    "        \n",
    "        # 1: Discretize\n",
    "        grid_pc = self.grid_ind(point_cloud).to(torch.long)\n",
    "       \n",
    "        unique_inds, counts = torch.unique(grid_pc, return_counts=True, dim=0)  \n",
    "        grid_indices = [unique_inds[:, i] for i in range(grid_pc.shape[1])]\n",
    "        \n",
    "        update[grid_indices] = update[grid_indices] + counts\n",
    "        \n",
    "        # 2: Apply BKI filters\n",
    "        filters = torch.sigmoid(torch.tensor(self.weights, device=self.device)).view(\n",
    "            1, 1, self.filter_size, self.filter_size, self.filter_size)\n",
    "        mid = torch.floor(self.filter_size / 2).to(torch.long)\n",
    "        filters[0, 0, mid, mid, mid] = 1\n",
    "        \n",
    "        update = torch.unsqueeze(update.permute(3, 0, 1, 2), 1)\n",
    "        update = F.conv3d(update, filters, padding=\"same\")\n",
    "        update = torch.squeeze(update).permute(1, 2, 3, 0)\n",
    "        \n",
    "        return current_map + update\n",
    "    \n",
    "    # def propagate(self, current_map, transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bki_map = DiscreteBKI(\n",
    "    torch.tensor([128, 128, 16]).to(device), # Grid size\n",
    "    torch.tensor([-25.6, -25.6, -2.0]).to(device), # Lower bound\n",
    "    torch.tensor([25.6, 25.6, 1.2]).to(device), # Upper bound\n",
    "    filter_size=3,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Add visualization\n",
    "map_pub = rospy.Publisher('SemMap', MarkerArray, queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point cloud from RELLIS\n",
    "velo_loc = os.path.join(dataset_loc, \"00004\", \"os1_cloud_node_kitti_bin\")\n",
    "label_base_loc = os.path.join(dataset_loc, \"00004\", \"os1_cloud_node_semantickitti_label_id\")\n",
    "os_files = os.listdir(velo_loc)\n",
    "\n",
    "curr_frame_id=0\n",
    "end_frame_id=0\n",
    "for velo_file in sorted(os_files):\n",
    "    velo = np.fromfile(os.path.join(velo_loc, velo_file), dtype=np.float32).reshape(-1, 4)[:, :3]\n",
    "    velo = torch.from_numpy(velo).to(device)\n",
    "    labels = np.fromfile(os.path.join(label_base_loc, velo_file.split(\".\")[0]+\".label\"), dtype=np.uint32)\n",
    "    labels_remapped = torch.from_numpy(LABELS_REMAP[labels]).to(device=device) # Remap labels to be contiguous\n",
    "    \n",
    "    # Ego vehicle = 0\n",
    "    non_void = labels_remapped != 0\n",
    "    velo = velo[non_void]\n",
    "    labels_remapped = labels_remapped[non_void]\n",
    "    \n",
    "    labeled_pc = torch.hstack( (velo, labels_remapped.reshape(-1, 1)) )\n",
    "    \n",
    "    non_dynamic = (labels_remapped != LABELS_REMAP[8]) & (labels_remapped != LABELS_REMAP[17])\n",
    "    labeled_pc = labeled_pc[non_dynamic]\n",
    "    \n",
    "    current_map = bki_map.initialize_grid()\n",
    "    posterior_map = bki_map(current_map, labeled_pc)\n",
    "\n",
    "    if curr_frame_id==end_frame_id:\n",
    "        break\n",
    "    curr_frame_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(torch.unique(torch.argmax(posterior_map, dim=-1), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, D, _ = posterior_map.shape\n",
    "\n",
    "publish_voxels(posterior_map, map_pub, \n",
    "    bki_map.centroids, \n",
    "    bki_map.min_bound.reshape(-1), \n",
    "    bki_map.max_bound.reshape(-1), \n",
    "    bki_map.grid_size.reshape(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Test 3D conv\n",
    "\n",
    "num_classes = 20\n",
    "\n",
    "# X, Y, Z\n",
    "filters = torch.zeros(27, dtype=torch.float)\n",
    "filters[13] = 1\n",
    "filters = filters.view(1, 1, 3, 3, 3)\n",
    "\n",
    "print(filters[0, 0, 1, :, :])\n",
    "\n",
    "inputs = torch.ones(num_classes, 1, 5, 5, 5)\n",
    "\n",
    "output = F.conv3d(inputs, filters, padding=\"same\")\n",
    "print(output[0, 0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_dir = os.path.join(dataset_loc, \"00004\", \"os1_cloud_node_semantickitti_label_id\", \"000000.label\")\n",
    "# pred_file = np.fromfile(pred_dir, dtype=np.uint32).reshape((-1))\n",
    "\n",
    "# pred_labels = pred_file & 0xFFFF\n",
    "# pdb.set_trace()\n",
    "# print(pred_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed publish map time  10.262082815170288\n",
      "> \u001b[0;32m/tmp/ipykernel_13721/2295623967.py\u001b[0m(44)\u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     41 \u001b[0;31m            bki_map.grid_size.reshape(-1))\n",
      "\u001b[0m\u001b[0;32m     42 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Elapsed publish map time \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurr_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 44 \u001b[0;31m    \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     45 \u001b[0;31m    \u001b[0mcurr_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb#ch0000009?line=41'>42</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mElapsed publish map time \u001b[39m\u001b[39m\"\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m curr_time)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb#ch0000009?line=42'>43</a>\u001b[0m     pdb\u001b[39m.\u001b[39mset_trace()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb#ch0000009?line=43'>44</a>\u001b[0m idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb#ch0000009?line=44'>45</a>\u001b[0m curr_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32m/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb#ch0000009?line=41'>42</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mElapsed publish map time \u001b[39m\u001b[39m\"\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m curr_time)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb#ch0000009?line=42'>43</a>\u001b[0m     pdb\u001b[39m.\u001b[39mset_trace()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb#ch0000009?line=43'>44</a>\u001b[0m idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthurzhang/CURLY/NeuralBKI/DiscreteBKI.ipynb#ch0000009?line=44'>45</a>\u001b[0m curr_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m/usr/lib/python3.8/bdb.py:88\u001b[0m, in \u001b[0;36mBdb.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/lib/python3.8/bdb.py?line=85'>86</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m# None\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/lib/python3.8/bdb.py?line=86'>87</a>\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mline\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='file:///usr/lib/python3.8/bdb.py?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_line(frame)\n\u001b[1;32m     <a href='file:///usr/lib/python3.8/bdb.py?line=88'>89</a>\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcall\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='file:///usr/lib/python3.8/bdb.py?line=89'>90</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_call(frame, arg)\n",
      "File \u001b[0;32m/usr/lib/python3.8/bdb.py:113\u001b[0m, in \u001b[0;36mBdb.dispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/bdb.py?line=110'>111</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_here(frame) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbreak_here(frame):\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/bdb.py?line=111'>112</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_line(frame)\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/bdb.py?line=112'>113</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquitting: \u001b[39mraise\u001b[39;00m BdbQuit\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/bdb.py?line=113'>114</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrace_dispatch\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Data.dataset import Rellis3dDataset\n",
    "\n",
    "train_dir = dataset_loc\n",
    "\n",
    "rellis_ds = Rellis3dDataset(directory=train_dir, device=device, num_frames=20, remap=True)\n",
    "dataloader_train = DataLoader(rellis_ds, batch_size=1, shuffle=False, collate_fn=rellis_ds.collate_fn, num_workers=2)\n",
    "\n",
    "idx = 0\n",
    "current_map = bki_map.initialize_grid()\n",
    "curr_time = time.time()\n",
    "for current_points, current_labels in dataloader_train:\n",
    "    batch_labeled_pc = torch.zeros(size=(0, 4), device=device)\n",
    "    for b in range(len(current_points)):\n",
    "        for f in range(len((current_points[b]))):\n",
    "            pc = torch.from_numpy(current_points[b][f]).to(device)\n",
    "            labels = torch.from_numpy(current_labels[b][f].astype(np.int32)).to(device).reshape(-1, 1)\n",
    "            labeled_pc = torch.hstack( (pc, labels))\n",
    "        batch_labeled_pc = torch.vstack((batch_labeled_pc, labeled_pc))\n",
    "\n",
    "    # Publish each point cloud to rviz\n",
    "    # publish_pc(batch_labeled_pc[:, 0:3], batch_labeled_pc[:, 3], map_pub, \n",
    "    #     bki_map.min_bound.reshape(-1), \n",
    "    #     bki_map.max_bound.reshape(-1), \n",
    "    #     bki_map.grid_size.reshape(-1)\n",
    "    # )\n",
    "    # print(\"Elapsed time for collating \", time.time() - curr_time)\n",
    "    curr_time = time.time()\n",
    "    posterior_map = bki_map(current_map, batch_labeled_pc)\n",
    "    # print(\"Elapsed time for forward pass \", time.time() - curr_time)\n",
    "    curr_time = time.time()\n",
    "\n",
    "    if idx%20==0:\n",
    "        publish_voxels(posterior_map, map_pub, \n",
    "            bki_map.centroids,\n",
    "            bki_map.min_bound.reshape(-1),\n",
    "            bki_map.max_bound.reshape(-1),\n",
    "            bki_map.grid_size.reshape(-1))\n",
    "        print(\"Elapsed publish map time \", time.time() - curr_time)\n",
    "        pdb.set_trace()\n",
    "    idx += 1\n",
    "    curr_time = time.time()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
